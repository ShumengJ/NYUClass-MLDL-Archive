{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShumengJ/ECEGY6143-ML-Archive/blob/main/8_convolutional_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvhG_zs5ySdK"
      },
      "source": [
        "# Convolutional neural networks\n",
        "\n",
        "_Fraida Fund_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWAUJy9uPV74"
      },
      "source": [
        "In this notebook, we will find out makes convolutional neural networks so powerful for computer vision applications!\n",
        "\n",
        "We will use three varieties of neural networks to classify our own handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYA7GQTpxNaX"
      },
      "source": [
        "Note: for faster training, use Runtime > Change Runtime Type to run this notebook on a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fczW6Z28QZRa"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxbX9rWm2yVA"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzHQ6FW5-tsk"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8gzuD6G-wNm"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWiuUhdX-z76"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9F2Fq2p-zbX"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3KU6czkazRl"
      },
      "source": [
        "## Train a fully connected neural network on MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCLOO9mKa56T"
      },
      "source": [
        "*Attribution: This section is based closely on [this demo notebook by Sundeep Rangan](https://github.com/sdrangan/introml/blob/master/unit09_neural/demo2_mnist_neural.ipynb)*\n",
        "\n",
        "First, we will train a simple neural network. We have:\n",
        "\n",
        "* One hidden layer with $N_H=100$ units, with sigmoid activation.\n",
        "* One output layer with $N_O=10$ units, one for each of the 10 possible classes. The output activation is softmax, which is used for multi-class targets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zh64tsMbBhX"
      },
      "source": [
        "First, we clear our session to make sure nothing is hanging around from previous models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iuzsPLWbC2N"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGA3TnkgbXFX"
      },
      "source": [
        "We will prepare our data by scaling it.\n",
        "\n",
        "We will also separate part of the training data to use for model tuning. The accuracy on this validation set will be used to determine when to stop training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7InBzM1bZhe"
      },
      "source": [
        "# scale\n",
        "X_train_nn = X_train/255.0\n",
        "X_test_nn = X_test/255.0\n",
        "\n",
        "# reshape\n",
        "X_train_nn = X_train_nn.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
        "X_test_nn = X_test_nn.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
        "\n",
        "# split training set so we can use part of it for model tuning\n",
        "X_train_nn, X_val_nn, y_train_nn, y_val_nn = train_test_split(X_train_nn, y_train, test_size=1.0/6.0)\n",
        "\n",
        "print(\"Training data shape\", X_train_nn.shape)\n",
        "print(\"Validation data shape\", X_val_nn.shape)\n",
        "print(\"Testing data shape\", X_test_nn.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm9PFMI9blnJ"
      },
      "source": [
        "Then, we can prepare our neural network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxmKV_wUbnOA"
      },
      "source": [
        "nin = X_train_nn.shape[1]  # dimension of input data\n",
        "nh = 512     # number of hidden units\n",
        "nout = 10   # number of outputs\n",
        "model_fc = Sequential()\n",
        "model_fc.add(Dense(units=nh, input_shape=(nin,), activation='relu', name='hidden'))\n",
        "model_fc.add(Dense(units=nout, activation='softmax', name='output'))\n",
        "model_fc.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur0DJwHabqMo"
      },
      "source": [
        "plot_model(model_fc, \"mnist-dense.png\", show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBXObvjWbxPa"
      },
      "source": [
        "To train the network, we have to select an optimizer and a loss function. Since this is a multi-class classification problem, we select the `sparse_categorical_crossentropy` loss. We use the Adam optimizer for our gradient descent.\n",
        "\n",
        "We also set the metrics that we wish to track during the optimization. In this case, we select accuracy on the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLjEbR5jbzEj"
      },
      "source": [
        "opt = optimizers.Adam(learning_rate=0.005)\n",
        "model_fc.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsD5ZDcLb074"
      },
      "source": [
        "Finally, we are ready to train our network. We wil specify the number of epochs and the batch size. We will also use a callback function to configure the training process to stop before the configured number of epochs, if no improvement in the validation set accuracy is observed for several epochs. We will also the restore the weights that had the best performance on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaxUOwWmb0f7"
      },
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max',\n",
        "                                      patience=5,restore_best_weights=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njaCVXF0b5TJ"
      },
      "source": [
        "Note that since the `fit` command is split across multiple lines, we cannot\n",
        "use the line-level magic command `%time` that we used previously to time it.\n",
        "Instead, we use the cell-level magic equivalent `%%time`,\n",
        "which reports the time to execute the entire cell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ6PfhSlb6u6"
      },
      "source": [
        "%%time\n",
        "hist = model_fc.fit(X_train_nn, y_train_nn,\n",
        "                       epochs=100, batch_size=128,\n",
        "                       validation_data=(X_val_nn,y_val_nn),\n",
        "                       callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCYKPQPbdC1r"
      },
      "source": [
        "Next, we plot the training accuracy and validation accuracy vs. the epoch number. This helps us understand whether our network is overfitted; we may suspect overfitting if the training performance is improving with additional training epochs while the validation performance is getting worse.\n",
        "\n",
        "In this case, we can see that we \"saturated\" the training accuracy at 100\\%, while the accuracy on the test set is a bit lower than that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS0u5x5SdEP8"
      },
      "source": [
        "tr_accuracy = hist.history['accuracy']\n",
        "val_accuracy = hist.history['val_accuracy']\n",
        "\n",
        "plt.plot(tr_accuracy);\n",
        "plt.plot(val_accuracy);\n",
        "plt.xlabel('epochs');\n",
        "plt.ylabel('accuracy');\n",
        "plt.legend(['training accuracy', 'validation accuracy']);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnfjF08Xdi6z"
      },
      "source": [
        "Now we can make predictions with our fitted model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCO16JK4dkGS"
      },
      "source": [
        "%time y_pred_prob_nn = model_fc.predict(X_test_nn)\n",
        "y_pred_nn = np.argmax(y_pred_prob_nn, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYUa3BmJdmiY"
      },
      "source": [
        "And compute accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl_RKrDmdnwi"
      },
      "source": [
        "acc = accuracy_score(y_test, y_pred_nn)\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbQfOtM5dqLJ"
      },
      "source": [
        "Note that we can also compute the accuracy with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUs-Ix6Ndrky"
      },
      "source": [
        "score = model_fc.evaluate(X_test_nn, y_test)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV1wpkfopQ_T"
      },
      "source": [
        "Our neural network does pretty well!  Currently, the state of the art (best result) on the MNIST dataset is 0.21% classification error - you can see some of the best-performing methods at [this link](https://benchmarks.ai/mnist).\n",
        "\n",
        "Furthermore, looking at some of the samples that are misclassified by our network, we can see that many of these samples are difficult for humans to classify as well. (Some may even be labeled incorrectly!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89vcyEK9pRZ0"
      },
      "source": [
        "num_samples = 10\n",
        "p = plt.figure(figsize=(num_samples*2,2))\n",
        "idxs_mis = np.flatnonzero(y_test!=y_pred_nn)\n",
        "idxs = np.random.choice(idxs_mis, num_samples, replace=False)\n",
        "for i, idx in enumerate(idxs):\n",
        "  p = plt.subplot(1, num_samples, i+1);\n",
        "  p = sns.heatmap(X_test[idx].astype('uint8'), cmap=plt.cm.gray,\n",
        "            xticklabels=False, yticklabels=False, cbar=False)\n",
        "  p = plt.axis('off');\n",
        "  p = plt.title(\"Sample %d \\n True label: %d \\n Prediction: %d\" % (idx, y_test[idx], y_pred_nn[idx]));\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOu21c06dvuR"
      },
      "source": [
        "## Try our fully connected neural network on our own test sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDOn-aC6gjeW"
      },
      "source": [
        "Now, let's try to classify our own test sample (as in a previous homework assignment).\n",
        "\n",
        "On a plain white piece of paper, in a black or other dark-colored pen, write a digit of your choice from 0 to 9. Take a photo of your handwritten digit.\n",
        "\n",
        "Edit your photo (crop, rotate as needed), using a photo editor of your choice (I used Google Photos), so that your photo is approximately square, and includes only the digit and the white background. Upload your image here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAhe-5UhfW9h"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVpdpctRenEK"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "filename = 'input.png'\n",
        "\n",
        "image = Image.open(filename)\n",
        "p = plt.imshow(np.asarray(image), cmap=plt.cm.gray,);\n",
        "p = plt.title('Shape: ' + str(np.asarray(image).shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enweLrmyfk4D"
      },
      "source": [
        "# convert to grayscale image - 'L' format means each pixel is\n",
        "# represented by a single value from 0 to 255\n",
        "image_bw = image.convert('L')\n",
        "p = plt.imshow(np.asarray(image_bw), cmap=plt.cm.gray,);\n",
        "p = plt.title('Shape: ' + str(np.asarray(image_bw).shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y8qXq--fmzF"
      },
      "source": [
        "# resize image\n",
        "image_bw_resized = image_bw.resize((28,28), Image.BICUBIC)\n",
        "p = plt.imshow(np.asarray(image_bw_resized), cmap=plt.cm.gray,);\n",
        "p = plt.title('Shape: ' + str(np.asarray(image_bw_resized).shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XaNmaLQfprG"
      },
      "source": [
        "# invert image, to match training data\n",
        "import PIL.ImageOps\n",
        "\n",
        "image_bw_resized_inverted = PIL.ImageOps.invert(image_bw_resized)\n",
        "p = plt.imshow(np.asarray(image_bw_resized_inverted), cmap=plt.cm.gray,);\n",
        "p = plt.title('Shape: ' + str(np.asarray(image_bw_resized_inverted).shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhDPgdRFfrjZ"
      },
      "source": [
        "# adjust contrast and scale\n",
        "pixel_filter = 20 # value from 0 to 100 - may need to adjust this manually\n",
        "min_pixel = np.percentile(image_bw_resized_inverted, pixel_filter)\n",
        "image_bw_resized_inverted_scaled = np.clip(image_bw_resized_inverted-min_pixel, 0, 255)\n",
        "max_pixel = np.max(image_bw_resized_inverted_scaled)\n",
        "image_bw_resized_inverted_scaled = np.asarray(image_bw_resized_inverted_scaled)/max_pixel\n",
        "p = plt.imshow(np.asarray(image_bw_resized_inverted_scaled), cmap=plt.cm.gray,);\n",
        "p = plt.title('Shape: ' + str(np.asarray(image_bw_resized_inverted_scaled).shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rW6s3iZfwpS"
      },
      "source": [
        "# finally, reshape to (1, 784) - 1 sample, 784 features\n",
        "test_sample = np.array(image_bw_resized_inverted_scaled).reshape(1,784)\n",
        "p = plt.imshow(np.reshape(test_sample, (28,28)), cmap=plt.cm.gray,);\n",
        "p = plt.title('Shape: ' + str(test_sample.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KMoXH1gf1Co"
      },
      "source": [
        "Now we can predict the class of this sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06FlTvANf3nT"
      },
      "source": [
        "test_probs = model_fc.predict(test_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNTDxPDYf9XM"
      },
      "source": [
        "sns.barplot(x=np.arange(0,10), y=test_probs.squeeze());\n",
        "plt.ylabel(\"Probability\");\n",
        "plt.xlabel(\"Class\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr-dgNKK--lw"
      },
      "source": [
        "### Things to try\n",
        "\n",
        "* What if we use a test sample where the image is not so well centered?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP6ZDZMxTlKz"
      },
      "source": [
        "## Background: Convolutional neural networks\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkWDaKGyGItf"
      },
      "source": [
        "The fully connected neural network was OK, but for images, there are important reasons why we will often prefer a convolutional neural network instead:\n",
        "\n",
        "* Dimension - images can have a huge number of pixels, and for image classification problems, we can also have a very large number of possible classes. A deep, fully connected network for these problems will have a *lot* of weights to learn.\n",
        "* Images (and videos!) have a structure that is wasted on the fully connected network.\n",
        "* Relevant features may be anywhere in the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yngU7EGOI20U"
      },
      "source": [
        "The key idea behind convolutional neural networks is that a \"neuron\" is connected to a small part of image at a time (locally connected).\n",
        "\n",
        "\n",
        "By having multiple locally connected neurons covering the entire image, we effectively “scan” the\n",
        "image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiGMKGM8MviT"
      },
      "source": [
        "What does convolution do? Let's look at a visual example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiMExbK0w6A2"
      },
      "source": [
        "This is a horizontal Sobel filter, which detects horizontal edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "red2bBW8M30a"
      },
      "source": [
        "horizontal_sobel = np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\n",
        "plt.imshow(horizontal_sobel, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O10qrsApErb1"
      },
      "source": [
        "This is an image of random noise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmWoeFAVNiOT"
      },
      "source": [
        "img = np.random.uniform(0,1,size=(10,10))\n",
        "plt.imshow(img, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yycF5ok6EtOA"
      },
      "source": [
        "The convolution of the Sobel filter and the random image doesn't pick up anything interesting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9AzVCTUN6_0"
      },
      "source": [
        "from scipy import signal\n",
        "img_conv = signal.correlate2d(img, horizontal_sobel, mode='same')\n",
        "plt.imshow(img_conv, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o66VfbXREzDC"
      },
      "source": [
        "What about the convolution of the Sobel filter and this digit?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5pydLApO5pV"
      },
      "source": [
        "img_index = 3675\n",
        "img = X_test[img_index]\n",
        "plt.imshow(img.reshape(28,28), cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilKvswmoPO_S"
      },
      "source": [
        "img_conv = signal.correlate2d(img.reshape(28,28), horizontal_sobel, mode='same')\n",
        "plt.imshow(img_conv, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pKkHaSTxD6F"
      },
      "source": [
        "This is a vertical Sobel filter, which detects vertical edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKiLvCAVPVLT"
      },
      "source": [
        "vertical_sobel =  np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
        "plt.imshow(horizontal_sobel, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuvneRjIE-3M"
      },
      "source": [
        "Look what it finds in the digit -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJR1U0p5PpSy"
      },
      "source": [
        "img_conv = signal.correlate2d(img.reshape(28,28), vertical_sobel, mode='same')\n",
        "plt.imshow(img_conv, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eTMNDmwQGPA"
      },
      "source": [
        "A convolutional layer is like an array of these filters - each one \"sweeps\" the image and looks for a different high-level \"feature\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67H-NKI4xLDQ"
      },
      "source": [
        "_Attribution: this example is based on a post by [Victor Zhou](https://victorzhou.com/blog/intro-to-cnns-part-1/)._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv11D41MFCDu"
      },
      "source": [
        "You can see a great interactive demo of the Sobel filters in [this tutorial on edge detection](https://cse442-17f.github.io/Sobel-Laplacian-and-Canny-Edge-Detection-Algorithms/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vPpBhx-Mu3e"
      },
      "source": [
        "## Train a convolutional neural network on MNIST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tny7Q4CMqb1"
      },
      "source": [
        "*Attribution: This section is based closely on [this demo notebook by Daniel Moser](https://github.com/AviatorMoser/keras-mnist-tutorial/blob/master/MNIST%20in%20Keras.ipynb)*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEIP9JXiTpKM"
      },
      "source": [
        "In this next section, we will train a convolutional neural network. Also, we will try to improve performance using the following techniques:\n",
        "\n",
        "* **Dropout layers**: Because deep networks can be prone to overfitting, we will also add _dropout_ layers to our network architecture. In each training stage, a dropout layer will \"zero\" a random selection of outputs (just for that stage). You can read more about this technique in [this paper](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf).\n",
        "* **Batch normalization**: This technique re-scales and centers the data in the mini-batch when applied between layers.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_4zuN0GTzYD"
      },
      "source": [
        "First, we clear our session to make sure nothing is hanging around from previous models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjDPeUIyRqhQ"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VJihh--T5iV"
      },
      "source": [
        "Then, we prepare our data. First, we reshape: the convolutional neural network requires each sample to have a 3D shape, including a depth - here, our image has only one color channel, so the depth is 1. We also scale and shift our data.\n",
        "\n",
        "We separate part of the training data to use for model tuning. The accuracy on this validation set will be used to determine when to stop training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0JqcFejQIFf"
      },
      "source": [
        "# reshape input to a 28x28x1 volume\n",
        "X_train_conv = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test_conv = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# scale\n",
        "X_train_conv = 2*(X_train_conv/255 - 0.5)\n",
        "X_test_conv = 2*(X_test_conv/255 - 0.5)\n",
        "\n",
        "# convert string classes to integer equivalents\n",
        "y_train = y_train.astype(np.int)\n",
        "y_test  = y_test.astype(np.int)\n",
        "\n",
        "# also add dimension to target\n",
        "y_train_conv = y_train.reshape(-1,1)\n",
        "y_test_conv = y_test.reshape(-1,1)\n",
        "\n",
        "# split training set so we can use part of it for model tuning\n",
        "X_train_conv, X_val_conv, y_train_conv, y_val_conv = train_test_split(X_train_conv, y_train_conv, test_size=1.0/6.0)\n",
        "\n",
        "print(\"Training data shape\", X_train_conv.shape)\n",
        "print(\"Validation data shape\", X_val_conv.shape)\n",
        "print(\"Testing data shape\", X_test_conv.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVKRaqFrT-MO"
      },
      "source": [
        "Next, we prepare our model with a sequence of `Conv2D`, `BatchNormalization`, `Activation`, `MaxPooling2D`, `Dropout`, and `Dense` layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNTFFXATQw4v"
      },
      "source": [
        "# Model parameters\n",
        "n_filters = 32                                      # number of convolutional filters to use\n",
        "pool_size = (2, 2)                                  # size of pooling area for max pooling\n",
        "kernel_size = (3, 3)                                # convolution kernel size\n",
        "input_shape = (28, 28, 1)                           # input image volume\n",
        "n_classes = 10                                      # number of classes\n",
        "\n",
        "model_conv = Sequential()                                 # Linear stacking of layers\n",
        "\n",
        "# Convolution Layer 1\n",
        "model_conv.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 3x3 kernels\n",
        "model_conv.add(BatchNormalization(axis=-1))               # normalize\n",
        "convLayer01 = Activation('relu')                          # activation\n",
        "model_conv.add(convLayer01)\n",
        "\n",
        "# Convolution Layer 2\n",
        "model_conv.add(Conv2D(32, (3, 3)))                        # 32 3x3 kernels\n",
        "model_conv.add(BatchNormalization(axis=-1))               # normalize\n",
        "model_conv.add(Activation('relu'))                        # activation\n",
        "convLayer02 = MaxPooling2D(pool_size=(2,2))               # Pool the max values over a 2x2 kernel\n",
        "model_conv.add(convLayer02)\n",
        "\n",
        "# Convolution Layer 3\n",
        "model_conv.add(Conv2D(64,(3, 3)))                         # 64 3x3 kernels\n",
        "model_conv.add(BatchNormalization(axis=-1))               # normalize\n",
        "convLayer03 = Activation('relu')                          # activation\n",
        "model_conv.add(convLayer03)\n",
        "\n",
        "# Convolution Layer 4\n",
        "model_conv.add(Conv2D(64, (3, 3)))                        # 64 3x3 kernels\n",
        "model_conv.add(BatchNormalization(axis=-1))               # normalize\n",
        "model_conv.add(Activation('relu'))                        # activation\n",
        "convLayer04 = MaxPooling2D(pool_size=(2,2))               # Pool the max values over a 2x2 kernel\n",
        "model_conv.add(convLayer04)\n",
        "model_conv.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
        "\n",
        "# Fully Connected Layer 5\n",
        "model_conv.add(Dense(512))                                # 512 fully connected nodes\n",
        "model_conv.add(BatchNormalization())                      # normalization\n",
        "model_conv.add(Activation('relu'))                        # activation\n",
        "\n",
        "# Fully Connected Layer 6\n",
        "model_conv.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
        "model_conv.add(Dense(10))                                 # final 10 fully connected nodes\n",
        "model_conv.add(Activation('softmax'))                     # softmax activation\n",
        "\n",
        "model_conv.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkVngaiJRKBv"
      },
      "source": [
        "plot_model(model_conv, \"mnist-convnet.png\", show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSRrmxgEUQvh"
      },
      "source": [
        "We will use the Adam optimizer again, and compile our model with `sparse_categorical_crossentropy` loss for backpropagation and `accuracy` for a scoring metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4sFNzR5RwDA"
      },
      "source": [
        "opt = optimizers.Adam(learning_rate=0.005)\n",
        "model_conv.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXxCmRCsVHVU"
      },
      "source": [
        "Next, we prepare our Early Stopping  callback. We will stop training if 5 epochs pass without an improvement in the validation accuracy, and at that point we will restore the model with the best validation accuracy seen so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdONxepfVI9E"
      },
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max',\n",
        "                                      patience=5,restore_best_weights=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2nnxtlShwhA"
      },
      "source": [
        "%%time\n",
        "# steps per epoch should be n_samples/batch_size\n",
        "hist = model_conv.fit(X_train_conv, y_train_conv,\n",
        "                           epochs = 20, batch_size=128,\n",
        "                           validation_data=(X_val_conv, y_val_conv),\n",
        "                           callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDASvCmoSVJC"
      },
      "source": [
        "tr_accuracy = hist.history['accuracy']\n",
        "val_accuracy = hist.history['val_accuracy']\n",
        "\n",
        "plt.plot(tr_accuracy);\n",
        "plt.plot(val_accuracy);\n",
        "plt.xlabel('epochs');\n",
        "plt.ylabel('accuracy');\n",
        "plt.legend(['Training accuracy', 'Validation accuracy']);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px6ArmK3S1Eq"
      },
      "source": [
        "%time y_pred_prob_conv = model_conv.predict(X_test_conv)\n",
        "y_pred_conv = np.argmax(y_pred_prob_conv, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qHdErWvTBRD"
      },
      "source": [
        "score = model_conv.evaluate(X_test_conv, y_test)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f3M2yXcDeuf"
      },
      "source": [
        "These are some of the samples that are misclassified:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PwSyJv2Dg2n"
      },
      "source": [
        "num_samples = 10\n",
        "p = plt.figure(figsize=(num_samples*2,2))\n",
        "idxs_mis = np.flatnonzero(y_test!=y_pred_conv)\n",
        "idxs = np.random.choice(idxs_mis, num_samples, replace=False)\n",
        "for i, idx in enumerate(idxs):\n",
        "  p = plt.subplot(1, num_samples, i+1);\n",
        "  p = sns.heatmap(X_test[idx].astype('uint8'), cmap=plt.cm.gray,\n",
        "            xticklabels=False, yticklabels=False, cbar=False)\n",
        "  p = plt.axis('off');\n",
        "  p = plt.title(\"Sample %d \\n True label: %d \\n Prediction: %d\" % (idx, y_test[idx], y_pred_conv[idx]));\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QygYdTHqjeTy"
      },
      "source": [
        "## Try our convolutional neural network on our own test sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsuTRqRl0uAH"
      },
      "source": [
        "We can use this convolutional neural network to predict the class of the test sample we uploaded previously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P49Jk6HdiUFy"
      },
      "source": [
        "test_sample_conv = test_sample.reshape(1, 28, 28, 1)\n",
        "test_sample_conv = 2*(test_sample_conv - 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjKAMC3SiRnh"
      },
      "source": [
        "test_probs = model_conv.predict(test_sample_conv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en-7GxNtyth-"
      },
      "source": [
        "plt.imshow(test_sample_conv.reshape(28, 28), cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em-hHZngitkM"
      },
      "source": [
        "sns.barplot(x=np.arange(0,10), y=test_probs.squeeze());\n",
        "plt.ylabel(\"Probability\");\n",
        "plt.xlabel(\"Class\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aYhPFHHo7Su"
      },
      "source": [
        "## Looking at output of convolutional layers\n",
        "\n",
        "Because deep learning is so complex, it can be difficult to understand why it makes the decisions it does. One way to better understand the behavior of a neural network is to visualize the output of each layer for a given input.\n",
        "\n",
        "We will select one input to examine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efkjowhao_3l"
      },
      "source": [
        "# choose an image to explore\n",
        "img_index = 3675\n",
        "img = X_test_conv[img_index]\n",
        "# add an extra dimension to it so it is in 4D\n",
        "img = img.reshape(1,28,28,1)\n",
        "plt.figure();\n",
        "plt.imshow(img.reshape(28,28), cmap='gray', interpolation='none');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwGMXUXD-sAl"
      },
      "source": [
        "from ipywidgets import interactive\n",
        "from ipywidgets import Layout\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def plot_layer(layer_idx):\n",
        "\n",
        "  convout1_f = K.function(model_conv.inputs, [model_conv.layers[layer_idx].output])\n",
        "  img = X_test_conv[img_index].reshape(1,28,28,1)\n",
        "  convolutions = np.squeeze(convout1_f(img))\n",
        "  if (len(convolutions.shape)) > 1:\n",
        "\n",
        "    m = convolutions.shape[2]\n",
        "    n = int(np.ceil(np.sqrt(m)))\n",
        "\n",
        "    # Visualization of each filter of the layer\n",
        "    fig = plt.figure(figsize=(15,12))\n",
        "    print(model_conv.layers[layer_idx].name)\n",
        "    for i in range(m):\n",
        "        ax = fig.add_subplot(n,n,i+1)\n",
        "        ax.imshow(convolutions[:,:,i], cmap='gray')\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "style = {'description_width': 'initial'}\n",
        "layout = Layout(width=\"800px\")\n",
        "layer_idx = widgets.IntSlider(min=0, max=13, value=0, style=style, layout=layout)\n",
        "interactive(plot_layer, layer_idx=layer_idx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PsFkChup6Rb"
      },
      "source": [
        "Generally, the convolutional layers close to the input capture small details, while those close to the output of the model capture more general features that are less sensitive to local variations in the input image. We can see this characteristic in the visualizations above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftJlkdth3z_Y"
      },
      "source": [
        "For a visualization with a more interesting image, see [this notebook](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb) by François Chollet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYVWqhHRkMww"
      },
      "source": [
        "## Saving and restoring a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N0BzeX4kOJh"
      },
      "source": [
        "Since this model took a long time to train, it may be useful to save the results, so that we can re-use the model later without having to re-train. We can save the model in an `hd5` file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwJtH4ShTKO9"
      },
      "source": [
        "model_conv.save(\"mnist_conv_mod.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxxOiR2NkQZk"
      },
      "source": [
        "Now, if you click on the folder icon in the menu on the left side of the Colab window, you can see this file in your workspace. You can download the file for later use.\n",
        "\n",
        "To use the model again in the future, you can load it using `load_model`, then use it to make predictions without having to train it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovk680GZTM_u"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model2 = load_model(\"mnist_conv_mod.h5\")\n",
        "opt = optimizers.Adam(learning_rate=0.005)\n",
        "model2.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# use saved model to predict new samples\n",
        "y_pred_prob_conv2 = model2.predict(X_test_conv)\n",
        "y_pred_conv2 = np.argmax(y_pred_prob_conv, axis=-1)\n",
        "acc = accuracy_score(y_test, y_pred_conv2)\n",
        "print(\"Accuracy of saved model on test set: %f\" % acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQIdPvYS_K_r"
      },
      "source": [
        "## With data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rtInSwq_qr0"
      },
      "source": [
        "We can try one more way to improve the model performance:\n",
        "\n",
        "* **Data augmentation**: To supply more training samples, we can provide slightly modified versions of training samples - for example, samples with a small rotation applied - on which to train the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajx0uznm_UkZ"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmQaeuAn_XP0"
      },
      "source": [
        "# Model parameters\n",
        "n_filters = 32                                      # number of convolutional filters to use\n",
        "pool_size = (2, 2)                                  # size of pooling area for max pooling\n",
        "kernel_size = (3, 3)                                # convolution kernel size\n",
        "input_shape = (28, 28, 1)                           # input image volume\n",
        "n_classes = 10                                      # number of classes\n",
        "\n",
        "model_aug = Sequential()                                 # Linear stacking of layers\n",
        "\n",
        "# Convolution Layer 1\n",
        "model_aug.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 3x3 kernels\n",
        "model_aug.add(BatchNormalization(axis=-1))               # normalize\n",
        "convLayer01 = Activation('relu')                     # activation\n",
        "model_aug.add(convLayer01)\n",
        "\n",
        "# Convolution Layer 2\n",
        "model_aug.add(Conv2D(32, (3, 3)))                        # 32 3x3 kernels\n",
        "model_aug.add(BatchNormalization(axis=-1))               # normalize\n",
        "model_aug.add(Activation('relu'))                        # activation\n",
        "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "model_aug.add(convLayer02)\n",
        "\n",
        "# Convolution Layer 3\n",
        "model_aug.add(Conv2D(64,(3, 3)))                         # 64 3x3 kernels\n",
        "model_aug.add(BatchNormalization(axis=-1))               # normalize\n",
        "convLayer03 = Activation('relu')                     # activation\n",
        "model_aug.add(convLayer03)\n",
        "\n",
        "# Convolution Layer 4\n",
        "model_aug.add(Conv2D(64, (3, 3)))                        # 64 3x3 kernels\n",
        "model_aug.add(BatchNormalization(axis=-1))               # normalize\n",
        "model_aug.add(Activation('relu'))                        # activation\n",
        "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "model_aug.add(convLayer04)\n",
        "model_aug.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
        "\n",
        "# Fully Connected Layer 5\n",
        "model_aug.add(Dense(512))                                # 512 fully connected nodes\n",
        "model_aug.add(BatchNormalization())                      # normalization\n",
        "model_aug.add(Activation('relu'))                        # activation\n",
        "\n",
        "# Fully Connected Layer 6\n",
        "model_aug.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
        "model_aug.add(Dense(10))                                 # final 10 fully connected nodes\n",
        "model_aug.add(Activation('softmax'))                     # softmax activation\n",
        "\n",
        "model_aug.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVPRFj2K0o3W"
      },
      "source": [
        "We convert the label data to a one-hot-encoded label and use categorical cross entropy loss in the model, because of an apparent bug that affects the current Keras version in Colab when using data augmentation. 🤷"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlmGSqejBH01"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "n_classes = 10\n",
        "ytr_cat =  to_categorical(y_train_conv, n_classes)\n",
        "yval_cat = to_categorical(y_val_conv, n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc4BjRe-_W2m"
      },
      "source": [
        "opt = optimizers.Adam(learning_rate=0.005)\n",
        "model_aug.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5j5zLL4_8A3"
      },
      "source": [
        "In the following cell, we will use the `ImageDataGenerator` in `keras` for data augmentation. This function will generate versions of the training images that have some image effects applied: rotation, shift, shear, zoom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS28EaE7_MNA"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
        "                         height_shift_range=0.08, zoom_range=0.08)\n",
        "train_generator = train_gen.flow(X_train_conv, ytr_cat, batch_size=128)\n",
        "\n",
        "val_gen = ImageDataGenerator()\n",
        "val_generator = val_gen.flow(X_val_conv, yval_cat, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wIng8Z1AB3P"
      },
      "source": [
        "To train our model with data augmentation, we will use the `fit_generator` function, and specify the number of steps per epoch as the number of samples divided by the batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wcHkeuk_PVi"
      },
      "source": [
        "%%time\n",
        "# steps per epoch should be n_samples/batch_size\n",
        "hist = model_aug.fit(train_generator,\n",
        "                           epochs = 20, steps_per_epoch=X_train_conv.shape[0]//128,\n",
        "                            validation_data = (X_val_conv, to_categorical(y_val_conv, n_classes)),\n",
        "                           callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcW827EvDms_"
      },
      "source": [
        "score = model_aug.evaluate(X_val_conv, to_categorical(y_val_conv, n_classes))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKaITlO0AHDj"
      },
      "source": [
        "tr_accuracy = hist.history['accuracy']\n",
        "val_accuracy = hist.history['val_accuracy']\n",
        "\n",
        "plt.plot(tr_accuracy);\n",
        "plt.plot(val_accuracy);\n",
        "plt.xlabel('epochs');\n",
        "plt.ylabel('accuracy');\n",
        "plt.legend(['training accuracy', 'validation accuracy']);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m2stcOgAJkD"
      },
      "source": [
        "%time y_pred_prob_aug = model_aug.predict(X_test_conv)\n",
        "y_pred_aug = np.argmax(y_pred_prob_aug, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DALCY29QBsth"
      },
      "source": [
        "score = model_aug.evaluate(X_test_conv, to_categorical(y_test, n_classes))\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R302NLhVATmI"
      },
      "source": [
        "These are some misclassified samples of this network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0MeS4bnATJm"
      },
      "source": [
        "num_samples = 10\n",
        "p = plt.figure(figsize=(num_samples*2,2))\n",
        "idxs_mis = np.flatnonzero(y_test!=y_pred_aug)\n",
        "idxs = np.random.choice(idxs_mis, num_samples, replace=False)\n",
        "for i, idx in enumerate(idxs):\n",
        "  p = plt.subplot(1, num_samples, i+1);\n",
        "  p = sns.heatmap(X_test[idx].astype('uint8'), cmap=plt.cm.gray,\n",
        "            xticklabels=False, yticklabels=False, cbar=False)\n",
        "  p = plt.axis('off');\n",
        "  p = plt.title(\"Sample %d \\n True label: %d \\n Prediction: %d\" % (idx, y_test[idx], y_pred_aug[idx]));\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1jlJ8GgAz2_"
      },
      "source": [
        "Now, let's see its performance on our own test sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfiaeeMNA1ac"
      },
      "source": [
        "test_probs = model_aug.predict(test_sample_conv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGxyqAfTB0E0"
      },
      "source": [
        "sns.barplot(x=np.arange(0,10), y=test_probs.squeeze());\n",
        "plt.ylabel(\"Probability\");\n",
        "plt.xlabel(\"Class\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYBof4o1B1_S"
      },
      "source": [
        "## Try more of your own test samples!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozQGeen3COU1"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5YI1zOIC7gd"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "filename = 'input2.png'\n",
        "\n",
        "image = Image.open(filename)\n",
        "image_bw = image.convert('L')\n",
        "image_bw_resized = image_bw.resize((28,28), Image.BICUBIC)\n",
        "image_bw_resized_inverted = PIL.ImageOps.invert(image_bw_resized)\n",
        "# adjust contrast and scale\n",
        "min_pixel = np.percentile(image_bw_resized_inverted, pixel_filter)\n",
        "image_bw_resized_inverted_scaled = np.clip(image_bw_resized_inverted-min_pixel, 0, 255)\n",
        "max_pixel = np.max(image_bw_resized_inverted)\n",
        "image_bw_resized_inverted_scaled = np.asarray(image_bw_resized_inverted_scaled)/max_pixel\n",
        "test_sample = np.array(image_bw_resized_inverted_scaled).reshape(1,784)\n",
        "test_sample_conv = test_sample.reshape(1, 28, 28, 1)\n",
        "test_sample_conv = 2*(test_sample_conv - 0.5)\n",
        "p = plt.imshow(np.reshape(test_sample, (28,28)), cmap=plt.cm.gray,);\n",
        "p = plt.title('Shape: ' + str(test_sample.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClhJPTMNCFv3"
      },
      "source": [
        "test_probs = model_fc.predict(test_sample)\n",
        "sns.barplot(x=np.arange(0,10), y=test_probs.squeeze());\n",
        "plt.ylabel(\"Probability\");\n",
        "plt.xlabel(\"Class\");\n",
        "plt.title(\"Fully connected network\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gNtmICTB_Pi"
      },
      "source": [
        "test_probs = model_conv.predict(test_sample_conv)\n",
        "sns.barplot(x=np.arange(0,10), y=test_probs.squeeze());\n",
        "plt.ylabel(\"Probability\");\n",
        "plt.xlabel(\"Class\");\n",
        "plt.title(\"Convolutional network\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOQEtMA4B4tx"
      },
      "source": [
        "test_probs = model_aug.predict(test_sample_conv)\n",
        "sns.barplot(x=np.arange(0,10), y=test_probs.squeeze());\n",
        "plt.ylabel(\"Probability\");\n",
        "plt.xlabel(\"Class\");\n",
        "plt.title(\"Convolutional network trained on augmented data\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt0kcKVZ4Nds"
      },
      "source": [
        "## Things to try\n",
        "\n",
        "* This notebook runs using a free GPU on Colab! Try changing the runtime to CPU: Runtime > Change Runtime Type and change Hardware Accelerator to CPU. Then run the notebook again. How much speedup did you get with the GPU, relative to CPU?"
      ]
    }
  ]
}