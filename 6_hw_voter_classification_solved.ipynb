{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShumengJ/ECEGY6143-ML-Archive/blob/main/6_hw_voter_classification_solved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amv64k835mG5"
      },
      "source": [
        "# Voter classification with exit poll data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbjmQWtb5rDV"
      },
      "source": [
        "In this notebook, we will explore the problem of voter classification.\n",
        "\n",
        "Given demographic data about a voter and their opinions on certain key issues, can we predict their vote in the 2016 U.S. presidential election? We will attempt this using a $k$ nearest neighbor classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-sACT_w0sXe"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2We-q6xZKhsk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import nan_euclidean_distances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf-2I7EYAfaS"
      },
      "source": [
        "We will need to install a library that is not in the default Colab environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbs7-58kAUSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deacdab8-9112-49f9-ce1e-f0196bf650b8"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.4.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.0)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDC9uR2yAWun"
      },
      "source": [
        "import category_encoders as ce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YRvbITr5zx1"
      },
      "source": [
        "## Load data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tkY5Qyw51P1"
      },
      "source": [
        "The data for this notebook comes from the [U.S. National Election Exit Day Polls](https://ropercenter.cornell.edu/exit-polls/us-national-election-day-exit-polls)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhgNpXYR1OkV"
      },
      "source": [
        "To get the data into Colab, click the file icon on the left side of the Colab workspace, then the upload icon. Upload the CSV file (`31116396_National2016.csv`) to your Colab workspace.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XezJJj5XKo07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "5ea43fad-fadc-4d1b-98d5-d457901189b8"
      },
      "source": [
        "df = pd.read_csv('31116396_National2016.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-d2daf1675d09>:1: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('31116396_National2016.csv')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ID             PRES                       HOU    WEIGHT @2WAYPRES16  \\\n",
              "0  135355  Hillary Clinton  The Democratic candidate  6.530935               \n",
              "1  135356  Hillary Clinton  The Democratic candidate  6.479016               \n",
              "2  135357  Hillary Clinton  The Democratic candidate  8.493230               \n",
              "3  135358  Hillary Clinton  The Democratic candidate  3.761814               \n",
              "4  135359  Hillary Clinton  The Democratic candidate  3.470473               \n",
              "\n",
              "     AGE   AGE3   AGE8  AGE45  AGE49  ... TRUMPWOMEN TRUMPWOMENB UNIONHH12  \\\n",
              "0  18-29  18-29  18-24  18-44  18-49  ...                                    \n",
              "1  18-29  18-29  25-29  18-44  18-49  ...                                    \n",
              "2  30-44  30-59  30-39  18-44  18-49  ...                                    \n",
              "3  30-44  30-59  30-39  18-44  18-49  ...                                    \n",
              "4  45-65  30-59  45-49    45+  18-49  ...                                    \n",
              "\n",
              "     VERSION VETVOTER WHITEREL WHNCLINC WHTEVANG WPROTBRN WPROTBRN3  \n",
              "0  Version 1                         No                              \n",
              "1  Version 1                         No                              \n",
              "2  Version 1                         No                              \n",
              "3  Version 1                         No                              \n",
              "4  Version 1                         No                              \n",
              "\n",
              "[5 rows x 138 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7b830f3-8a38-40db-bbf9-8154c9b308d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>PRES</th>\n",
              "      <th>HOU</th>\n",
              "      <th>WEIGHT</th>\n",
              "      <th>@2WAYPRES16</th>\n",
              "      <th>AGE</th>\n",
              "      <th>AGE3</th>\n",
              "      <th>AGE8</th>\n",
              "      <th>AGE45</th>\n",
              "      <th>AGE49</th>\n",
              "      <th>...</th>\n",
              "      <th>TRUMPWOMEN</th>\n",
              "      <th>TRUMPWOMENB</th>\n",
              "      <th>UNIONHH12</th>\n",
              "      <th>VERSION</th>\n",
              "      <th>VETVOTER</th>\n",
              "      <th>WHITEREL</th>\n",
              "      <th>WHNCLINC</th>\n",
              "      <th>WHTEVANG</th>\n",
              "      <th>WPROTBRN</th>\n",
              "      <th>WPROTBRN3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>135355</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>The Democratic candidate</td>\n",
              "      <td>6.530935</td>\n",
              "      <td></td>\n",
              "      <td>18-29</td>\n",
              "      <td>18-29</td>\n",
              "      <td>18-24</td>\n",
              "      <td>18-44</td>\n",
              "      <td>18-49</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Version 1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>135356</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>The Democratic candidate</td>\n",
              "      <td>6.479016</td>\n",
              "      <td></td>\n",
              "      <td>18-29</td>\n",
              "      <td>18-29</td>\n",
              "      <td>25-29</td>\n",
              "      <td>18-44</td>\n",
              "      <td>18-49</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Version 1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>135357</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>The Democratic candidate</td>\n",
              "      <td>8.493230</td>\n",
              "      <td></td>\n",
              "      <td>30-44</td>\n",
              "      <td>30-59</td>\n",
              "      <td>30-39</td>\n",
              "      <td>18-44</td>\n",
              "      <td>18-49</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Version 1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>135358</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>The Democratic candidate</td>\n",
              "      <td>3.761814</td>\n",
              "      <td></td>\n",
              "      <td>30-44</td>\n",
              "      <td>30-59</td>\n",
              "      <td>30-39</td>\n",
              "      <td>18-44</td>\n",
              "      <td>18-49</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Version 1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>135359</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>The Democratic candidate</td>\n",
              "      <td>3.470473</td>\n",
              "      <td></td>\n",
              "      <td>45-65</td>\n",
              "      <td>30-59</td>\n",
              "      <td>45-49</td>\n",
              "      <td>45+</td>\n",
              "      <td>18-49</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Version 1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 138 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7b830f3-8a38-40db-bbf9-8154c9b308d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7b830f3-8a38-40db-bbf9-8154c9b308d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7b830f3-8a38-40db-bbf9-8154c9b308d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngcKmjOIJnRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd39710-d442-4fe7-f130-fefdfd682c13"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25034, 138)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aNl-tr1B1cF"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swuHzBEY6ZgH"
      },
      "source": [
        "df.replace(\" \", float(\"NaN\"), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBH0quOZB0Yx"
      },
      "source": [
        "Encode target variable as a binary variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQuEBEDVDxpO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44561493-6fa7-40be-f2ee-f3d6469f8c98"
      },
      "source": [
        "df = df[df['PRES'].isin(['Donald Trump', 'Hillary Clinton'])]\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 22798 entries, 0 to 25033\n",
            "Columns: 138 entries, ID to WPROTBRN3\n",
            "dtypes: float64(1), int64(2), object(135)\n",
            "memory usage: 24.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ytG1hEaCl-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d92f23-a55a-4333-9883-d29c30d7f44a"
      },
      "source": [
        "y = df['PRES'].map({'Donald Trump': 1, 'Hillary Clinton': 0})\n",
        "y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    12126\n",
              "1    10672\n",
              "Name: PRES, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz46dzG4JyU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad9e0e3-a3dc-4272-9135-7cc6db476e5a"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22798, 138)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMAmRW6JWCkJ"
      },
      "source": [
        "## Add features to your classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1p3n_YUWGZY"
      },
      "source": [
        "For this assignment, we try to improve the performance of the classifier by adding additional features, such as:\n",
        "\n",
        "* More demographic information: `INCOME16GEN`, `MARRIED`, `RELIGN10`, `ATTEND16`, `LGBT`, `VETVOTER`\n",
        "* Opinions about political issues and about what factors are most important in determining which candidate to vote for: `TRACK`, `SUPREME16`,  `FINSIT`, `IMMWALL`, `ISIS16`, `LIFE`, `TRADE16`, `HEALTHCARE16`, `GOVTDO10`, `GOVTANGR16`, `QLT16`, `ISSUE16`, `NEC`\n",
        "\n",
        "\n",
        "(We will not use questions that directly ask the participants how they feel about individual candidates, or about their party affiliation or political leaning.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3QSLOyHalt1"
      },
      "source": [
        "The basic requirement is to add:\n",
        "\n",
        "* four features that are encoded using ordinal encoding, and\n",
        "* four features that are encoded using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RYyVEf9_qNt"
      },
      "source": [
        "features = ['EDUC12R', 'AGE', 'RACE', 'INCOME16GEN', 'MARRIED', 'RELIGN10', 'ATTEND16', 'LGBT', 'VETVOTER',\n",
        "            'TRACK', 'SUPREME16',  'FINSIT', 'IMMWALL', 'ISIS16', 'LIFE',\n",
        "            'TRADE16', 'HEALTHCARE16', 'GOVTDO10', 'GOVTANGR16', 'QLT16',\n",
        "            'ISSUE16', 'NEC']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1iHLsEv0Su8"
      },
      "source": [
        "In my solution, I will add more than four of each - but that's not required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0na85xQ2qIMp"
      },
      "source": [
        "## Encode ordinal features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhNksoCEAqy3"
      },
      "source": [
        "The following features should be encoded using ordinal encoding. They should not be encoded with one-hot encoding, since there is a logical sequence to the potential values in each feature. Using ordinal encoding preserves this sequence for the distance computation.\n",
        "\n",
        "The mapping for each feature should reflect the logical order of the possible values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W1VtqkFqJj0"
      },
      "source": [
        "mapping_dict = {'col': 'AGE', 'mapping':\n",
        "                {'18-29': 1,\n",
        "                 '30-44': 2,\n",
        "                 '45-65': 3,\n",
        "                 '65+': 4}\n",
        "                }, {'col': 'EDUC12R', 'mapping':\n",
        "                  {'High school or less': 1,\n",
        "                   'Some college/assoc. degree': 2,\n",
        "                   'College graduate': 3,\n",
        "                   'Postgraduate study': 4}\n",
        "                    }, {'col': 'INCOME16GEN', 'mapping':\n",
        "                  {'Under $30,000': 1,\n",
        "                   '$30,000-$49,999': 2,\n",
        "                   '$50,000-$99,999': 3,\n",
        "                   '$100,000-$199,999': 4,\n",
        "                   '$200.000-$249,999': 5,\n",
        "                   '$250,000 or more': 6}\n",
        "                    }, {'col': 'GOVTANGR16', 'mapping':\n",
        "                  {'Angry': 1,\n",
        "                   'Dissatisfied, but not angry': 2,\n",
        "                   'Satisfied, but not enthusiastic': 3,\n",
        "                   'Enthusiastic': 4,\n",
        "                   'Omit': -1}\n",
        "                    }, {'col': 'ATTEND16', 'mapping':\n",
        "                  {'Never': 1,\n",
        "                   'A few times a year': 2,\n",
        "                   'A few times a month': 3,\n",
        "                   'Once a week or more': 4}\n",
        "                    }, {'col': 'SUPREME16', 'mapping':\n",
        "                  {'Not a factor at all': 1,\n",
        "                   'A minor factor': 2,\n",
        "                   'An important factor': 3,\n",
        "                   'The most important factor': 4,\n",
        "                   'Omit': -1}\n",
        "                    }, {'col': 'ISIS16', 'mapping':\n",
        "                  {'Very badly': 1,\n",
        "                   'Somewhat badly': 2,\n",
        "                   'Somewhat well': 3,\n",
        "                   'Very well': 4,\n",
        "                   'Omit': -1}\n",
        "                    }, {'col': 'LIFE', 'mapping':\n",
        "                  {'Worse than life today': 1,\n",
        "                   'About the same': 2,\n",
        "                   'Better than life today': 3,\n",
        "                   'Omit': -1}\n",
        "                    }, {'col': 'NEC', 'mapping':\n",
        "                  {'Excellent': 1,\n",
        "                   'Good': 2,\n",
        "                   'Not so good': 3,\n",
        "                   'Poor': 4,\n",
        "                   'Omit': -1}\n",
        "                    }, {'col': 'HEALTHCARE16', 'mapping':\n",
        "                  {'Went too far': 1,\n",
        "                   'Was about right': 2,\n",
        "                   'Did not go far enough': 3,\n",
        "                   'Omit': -1}\n",
        "                    }, {'col': 'FINSIT', 'mapping':\n",
        "                  {'Worse today': 1,\n",
        "                   'About the same': 2,\n",
        "                   'Better today': 3,\n",
        "                   'Omit': -1}\n",
        "                    }, {'col': 'TRADE16', 'mapping':\n",
        "                  {'Takes away U.S. jobs': 1,\n",
        "                   'Has no effect on U.S. jobs': 2,\n",
        "                   'Creates more U.S. jobs': 3,\n",
        "                   'Omit': -1}\n",
        "                    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL-FKKsKvSrP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "ea594f8c-e769-4d98-b823-c83274b766ea"
      },
      "source": [
        "features_ord = ['EDUC12R', 'AGE', 'INCOME16GEN', 'ATTEND16', 'SUPREME16', 'ISIS16', 'LIFE', 'GOVTANGR16', 'NEC', 'HEALTHCARE16', 'FINSIT', 'TRADE16']\n",
        "\n",
        "enc_ord = ce.OrdinalEncoder(handle_missing='return_nan', mapping=mapping_dict)\n",
        "enc_ord.fit(df[features_ord])\n",
        "\n",
        "df_v2_ord = enc_ord.transform(df[features_ord])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-aca35bdcd1e2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeatures_ord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'EDUC12R'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AGE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INCOME16GEN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ATTEND16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SUPREME16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ISIS16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LIFE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GOVTANGR16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NEC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HEALTHCARE16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FINSIT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TRADE16'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menc_ord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'return_nan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0menc_ord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_ord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/category_encoders/ordinal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, verbose, mapping, cols, drop_invariant, return_df, handle_unknown, handle_missing)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping_supplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping_supplied\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_supplied_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/category_encoders/ordinal.py\u001b[0m in \u001b[0;36m_validate_supplied_mapping\u001b[0;34m(self, supplied_mapping)\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0;34m\"For an example refer to the documentation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupplied_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmapping_el\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupplied_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping_el\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid supplied mapping, must be of type List[Dict[str, Union[Dict, pd.Series]]].For an example refer to the documentation"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi-msCtgJiEe"
      },
      "source": [
        "df_v2_ord.replace(-1, float(\"NaN\"), inplace=True)\n",
        "\n",
        "for col in df_v2_ord.columns:\n",
        "  df_v2_ord[col] = df_v2_ord[col]-df_v2_ord[col].min(skipna=True)\n",
        "  df_v2_ord[col] = df_v2_ord[col]/df_v2_ord[col].max(skipna=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYdhWA2IBVc5"
      },
      "source": [
        "df_v2_ord.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5mrBIRi-6Ta"
      },
      "source": [
        "## Encode binary features\n",
        "\n",
        "\n",
        "Features with two possible values can be encoded either way, as ordinal features or using one-hot encoding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2jmR_Jda5cd"
      },
      "source": [
        "features_bin = ['SEX', 'MARRIED', 'LGBT', 'TRACK', 'VETVOTER', 'IMMWALL', 'GOVTDO10']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwu5dMlabC46"
      },
      "source": [
        "Here is how you could encode them using ordinal encoding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttCo1Klp_Er1"
      },
      "source": [
        "mapping_dict = {'col': 'SEX', 'mapping':\n",
        "                {'Female': 1,\n",
        "                 'Male': 2,\n",
        "                 'Omit': -1}\n",
        "                },{'col': 'MARRIED', 'mapping':\n",
        "                {'No': 1,\n",
        "                 'Yes': 2,\n",
        "                 'Omit': -1}\n",
        "                },{'col': 'LGBT', 'mapping':\n",
        "                {'No': 1,\n",
        "                 'Yes': 2,\n",
        "                 'Omit': -1}\n",
        "                },{'col': 'TRACK', 'mapping':\n",
        "                {'Seriously off on the wrong track': 1,\n",
        "                 'Generally going in the right direction': 2,\n",
        "                 'Omit': -1}\n",
        "                },{'col': 'VETVOTER', 'mapping':\n",
        "                {'No': 1,\n",
        "                 'Yes': 2,\n",
        "                 'Omit': -1}\n",
        "                },{'col': 'IMMWALL', 'mapping':\n",
        "                {'Oppose': 1,\n",
        "                 'Support': 2,\n",
        "                 'Omit': -1}\n",
        "                },{'col': 'GOVTDO10', 'mapping':\n",
        "                {'Government is doing too many things better left to businesses and individuals': 1,\n",
        "                 'Government should do more to solve problems': 2,\n",
        "                 'Omit': -1}\n",
        "                },\n",
        "\n",
        "enc_bin = ce.OrdinalEncoder(handle_missing='return_nan', mapping=mapping_dict)\n",
        "enc_bin.fit(df[features_bin])\n",
        "\n",
        "df_v2_bin_ord = enc_bin.transform(df[features_bin])\n",
        "df_v2_bin_ord.replace(-1, float(\"NaN\"), inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKHcfqtU_ggA"
      },
      "source": [
        "for col in df_v2_bin_ord.columns:\n",
        "  df_v2_bin_ord[col] = df_v2_bin_ord[col]-df_v2_bin_ord[col].min(skipna=True)\n",
        "  df_v2_bin_ord[col] = df_v2_bin_ord[col]/df_v2_bin_ord[col].max(skipna=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgM-gYxZ_lH2"
      },
      "source": [
        "df_v2_bin_ord.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdhsEyEpbHjP"
      },
      "source": [
        "Here is how you could encode them using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zfL3CITaAAY"
      },
      "source": [
        "enc_bin = ce.OneHotEncoder(use_cat_names=True)\n",
        "enc_bin.fit(df[features_bin])\n",
        "\n",
        "df_v2_bin_oh = enc_bin.transform(df[features_bin])\n",
        "\n",
        "\n",
        "df_v2_bin_oh.drop(['SEX_nan', 'MARRIED_nan', 'LGBT_nan', 'TRACK_nan', 'TRACK_Omit',\n",
        "               'VETVOTER_nan', 'IMMWALL_nan', 'IMMWALL_Omit', 'GOVTDO10_nan', 'GOVTDO10_Omit'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSqTwqIaabtM"
      },
      "source": [
        "df_v2_bin_oh.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9aznmcSaFFV"
      },
      "source": [
        "df_v2_bin_oh.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsfHdOuGqcBs"
      },
      "source": [
        "## Encode categorical features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuJHHlmvDGqe"
      },
      "source": [
        "The following features should be encoded with one-hot encoding. Ordinal encoding of these features would imply an ordering that doesn't actually exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvUeenAjqeMK"
      },
      "source": [
        "features_oh =  ['RACE', 'ISSUE16', 'QLT16', 'RELIGN10']\n",
        "enc_oh = ce.OneHotEncoder(use_cat_names=True)\n",
        "\n",
        "enc_oh.fit(df[features_oh])\n",
        "\n",
        "df_v2_oh = enc_oh.transform(df[features_oh])\n",
        "\n",
        "\n",
        "df_v2_oh.drop(['RACE_nan', 'ISSUE16_nan', 'ISSUE16_Omit', 'QLT16_Omit',\n",
        "               'QLT16_nan', 'RELIGN10_nan'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5ZUyvOvsmxC"
      },
      "source": [
        "df_v2_oh.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrtpaLi5Ia6M"
      },
      "source": [
        "df_v2_oh.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzkjKx88qwZp"
      },
      "source": [
        "## Split data into training and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb6EBZmXD4OB"
      },
      "source": [
        "Next, split data into a training set and a test set, with 25% of the data reserved for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wsUh2hbIAVY"
      },
      "source": [
        "df_combined = pd.concat([df_v2_ord, df_v2_bin_oh, df_v2_oh, pd.DataFrame(y)], axis=1)\n",
        "df_combined.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgnOrFs9B0DX"
      },
      "source": [
        "df_combined.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBk4LDip0mL1"
      },
      "source": [
        "Since I plan to try a few different variations on the data - some with different types of encoding, some with only a subset of features - and I want to evaluate them all with the same train-test split, I'm going to just get the indices of the training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppA0Z8Icg-nn"
      },
      "source": [
        "idx_train, idx_test = train_test_split(np.arange(0, df_combined.shape[0]), test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGT5QkQi06DM"
      },
      "source": [
        "Then I can use these indices to get the training and test feature matrices and label vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlmThNH0g9iG"
      },
      "source": [
        "X_train = df_combined.drop(['PRES'], axis=1).iloc[idx_train]\n",
        "y_train = df_combined['PRES'].iloc[idx_train]\n",
        "\n",
        "X_test = df_combined.drop(['PRES'], axis=1).iloc[idx_test]\n",
        "y_test = df_combined['PRES'].iloc[idx_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0zHO3aZlsrJ"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk9CWgHeAygn"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaZmURFQrq76"
      },
      "source": [
        "## Train a $k$ nearest neighbors classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9DGxKopEMT7"
      },
      "source": [
        "Now, we cam train a $k$ nearest neighbors classifier, using pre-computed distances with `nan_euclidean_distances`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4LfbHRpEp__"
      },
      "source": [
        "After we \"train\" our classifier, we evaluate its accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex6Egy8lvDJP"
      },
      "source": [
        "distances_train = nan_euclidean_distances(np.array(X_train)) # distance between rows of X\n",
        "distances_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d8e0CAmlf4v"
      },
      "source": [
        "distances_test = nan_euclidean_distances(np.array(X_test),np.array(X_train))\n",
        "distances_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toeBGi60qkcW"
      },
      "source": [
        "Use K-fold CV to select k:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g9JDZfBqdBB"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "n_fold = 5\n",
        "k_list = np.arange(1, 101, 10)\n",
        "n_k = len(k_list)\n",
        "acc_list = np.zeros((n_k, n_fold))\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "kf.get_n_splits(X_train)\n",
        "\n",
        "print(kf)\n",
        "\n",
        "for isplit, idx in tqdm( enumerate(kf.split(X_train)), total=n_fold, desc=\"K-fold\"):\n",
        "\n",
        "  train_index, val_index = idx\n",
        "  y_train_kfold = np.array(y_train)[train_index]\n",
        "  y_val_kfold = np.array(y_train)[val_index]\n",
        "\n",
        "  for idx_k, k in enumerate(k_list):\n",
        "    distances_train_kfold = distances_train[train_index[:, None], train_index]\n",
        "    distances_val_kfold = distances_train[val_index[:, None], train_index]\n",
        "\n",
        "    clf = KNeighborsClassifier(n_neighbors=k, metric='precomputed', n_jobs=-1)\n",
        "    clf.fit(distances_train_kfold, y_train_kfold)\n",
        "\n",
        "    y_pred = clf.predict(distances_val_kfold)\n",
        "    acc_list[idx_k, isplit] = accuracy_score(y_val_kfold, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7NoM8hC3Rso"
      },
      "source": [
        "# delete these variables we don't need anymore, to free up memory\n",
        "del(distances_train_kfold)\n",
        "del(distances_val_kfold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZETF2fGhqnHd"
      },
      "source": [
        "plt.errorbar(x=k_list, y=acc_list.mean(axis=1), yerr=acc_list.std(axis=1)/np.sqrt(n_fold-1));\n",
        "\n",
        "plt.xlabel(\"k (number of neighbors)\");\n",
        "plt.ylabel(\"K-fold accuracy\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4YtklPiqxr5"
      },
      "source": [
        "Using this, we can select $k$ and then re-fit our model using this value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq0avB4pyj0l"
      },
      "source": [
        "k_opt=k_list[np.argmax(acc_list.mean(axis=1))]\n",
        "print(k_opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeKxCrNurtO_"
      },
      "source": [
        "clf = KNeighborsClassifier(n_neighbors=k_opt, metric='precomputed')\n",
        "clf.fit(distances_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8tAJizbrweN"
      },
      "source": [
        "y_pred = clf.predict(distances_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iUj0ro4r1Io"
      },
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMUJ7IslRj3W"
      },
      "source": [
        "With ordinal encoding for the binary features, the accuracy may be somewhat lower:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niIFmR1La0Aq"
      },
      "source": [
        "df_combined_ord = pd.concat([df_v2_ord, df_v2_bin_ord, df_v2_oh, pd.DataFrame(y)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_3AMl-JhL7N"
      },
      "source": [
        "X_train = df_combined_ord.drop(['PRES'], axis=1).iloc[idx_train]\n",
        "y_train = df_combined_ord['PRES'].iloc[idx_train]\n",
        "\n",
        "X_test = df_combined_ord.drop(['PRES'], axis=1).iloc[idx_test]\n",
        "y_test = df_combined_ord['PRES'].iloc[idx_test]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ66ZZWdjuR1"
      },
      "source": [
        "X_train.reset_index(inplace=True, drop=True)\n",
        "y_train.reset_index(inplace=True, drop=True)\n",
        "\n",
        "X_test.reset_index(inplace=True, drop=True)\n",
        "y_test.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik9yKAMaa_fc"
      },
      "source": [
        "distances_test = nan_euclidean_distances(np.array(X_test),np.array(X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMwD_dEfj4aT"
      },
      "source": [
        "distances_train = nan_euclidean_distances(np.array(X_train)) # distance between rows of X\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=k_opt, metric='precomputed')\n",
        "clf.fit(distances_train, y_train)\n",
        "y_pred = clf.predict(distances_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSbak8C5bDrZ"
      },
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctVDVrNJRvBf"
      },
      "source": [
        "For this assignment, there is no specific accuracy target you had to hit. But if you want to learn more about how to improve the accuracy of the model, continue to the \"bonus\" section!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMY1dRP6GNe1"
      },
      "source": [
        "## Bonus: Improve our $k$ nearest neighbor model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti_i7GSWbZmG"
      },
      "source": [
        "Is the $k$ nearest neighbor model good? It achieves an accuracy that is well above the accuracy of a classifier that always predicts the majority vote.\n",
        "\n",
        "But, we can do better - there are some problems with our data preparation and with our model. If we fix these, we may achieve better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmGX62tdbv-V"
      },
      "source": [
        "### Bonus: Pass NaNs through the one-hot encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf8ANkOJGb_R"
      },
      "source": [
        "The first problem is with the one-hot encoder that we used. Note that unlike the ordinal encoder, we didn't pass NaN values through the encoder.\n",
        "\n",
        "What are the consequences of this?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHRkAF2UcA-z"
      },
      "source": [
        "For a sample that is missing the value of a one-hot encoded feature, a 0 will be recorded for all of the columns corresponding to that feature.\n",
        "\n",
        "For example, suppose a sample has no recorded answer to the `ISSUE16` question. Our one-hot encoder will transform this feature into four columns: `ISSUE16_Foreign policy`, `ISSUE16_The economy`, `ISSUE16_Terrorism`, `ISSUE16_Immigration`. The sample with no recorded answer will have a 0 in all four columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtRmpsh0b0bL"
      },
      "source": [
        " This means that the `ISSUE16` feature will be included in the pairwise distance computation, even if one sample in the pair is missing that value. The distance from a sample with no response to the `ISSUE16` question to one with a response (any response) in the `ISSUE16` question is greater than the distance between two samples that have no response to the `ISSUE16` question.\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kjIXiPJc4uR"
      },
      "source": [
        "That is not the desired behavior - we said that if a sample is missing a response for a particular feature, the feature should not be included in distance computations involving that sample, since we just don't know anything about the respondent's views on that issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaEmXiS4OMta"
      },
      "source": [
        "If that's the case, why didn't we pass through NaNs in our one-hot encoder? Let's see what happens if we do:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkRFR5iNGO7U"
      },
      "source": [
        "enc_oh = ce.OneHotEncoder(use_cat_names=True, handle_missing='return_nan')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9gBB9aDQjqP"
      },
      "source": [
        "enc_oh.fit(df[features_oh])\n",
        "\n",
        "df_v2_oh_nan = enc_oh.transform(df[features_oh])\n",
        "\n",
        "\n",
        "df_v2_oh_nan.drop(['RACE_nan', 'ISSUE16_nan', 'ISSUE16_Omit', 'QLT16_Omit',\n",
        "               'QLT16_nan', 'RELIGN10_nan'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7EttowvQrmz"
      },
      "source": [
        "df_v2_oh_nan.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuZZg-gQQvPv"
      },
      "source": [
        "df_v2_oh_nan.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBoFMxyz4fPr"
      },
      "source": [
        "Now my combined data frame includes the ordinal-encoded features (with NaNs passed through), ordinal-encoded binary features (with NaNs passed through), and one-hot encoded features (with NaNs passed through)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njc_aYsjQ1ON"
      },
      "source": [
        "df_combined_nan = pd.concat([df_v2_ord, df_v2_bin_ord, df_v2_oh_nan, pd.DataFrame(y)], axis=1)\n",
        "df_combined_nan.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY2lqpiPdLF7"
      },
      "source": [
        "Note that we now have a correct count of the number of non-missing values for each feature. Every single column (besides for `PRES`) has some NaNs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F_RgcsbRN9q"
      },
      "source": [
        "df_combined_nan.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHk1tj2RgIJj"
      },
      "source": [
        "X_train = df_combined_nan.drop(['PRES'], axis=1).iloc[idx_train]\n",
        "y_train = df_combined_nan['PRES'].iloc[idx_train]\n",
        "\n",
        "X_test = df_combined_nan.drop(['PRES'], axis=1).iloc[idx_test]\n",
        "y_test = df_combined_nan['PRES'].iloc[idx_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74a3Nvz6Ri6j"
      },
      "source": [
        "distances_train = nan_euclidean_distances(np.array(X_train)) # distance between rows of X\n",
        "distances_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhTEseF_R1Pt"
      },
      "source": [
        "distances_test = nan_euclidean_distances(np.array(X_test),np.array(X_train))\n",
        "distances_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-tET2c1Thux"
      },
      "source": [
        "But, if we try to fit a $k$ neighbors classifier, it will fail with the error message:\n",
        "\n",
        "```\n",
        "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
        "```\n",
        "\n",
        "because the distance matrix contains NaNs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-g6IDkTTj7M"
      },
      "source": [
        "clf = KNeighborsClassifier(n_neighbors=k_opt, metric='precomputed', n_jobs=-1)\n",
        "clf.fit(distances_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5VZz1WHUrvu"
      },
      "source": [
        "So if we put NaNs through the one-hot encoder, we can't use the KNeighborsClassifier in scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlIjBj9OTz8Z"
      },
      "source": [
        "Instead, we have to implement our own $k$ nearest neighbors using `numpy` directly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzfrXNkkUFsM"
      },
      "source": [
        "X_train.reset_index(inplace=True, drop=True)\n",
        "y_train.reset_index(inplace=True, drop=True)\n",
        "\n",
        "X_test.reset_index(inplace=True, drop=True)\n",
        "y_test.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLoc_A6NT6Gk"
      },
      "source": [
        "y_pred = [y_train.loc[np.argsort(dist)[:k_opt]].mode() for dist in distances_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2b5PFRyURs5"
      },
      "source": [
        "acc = accuracy_score(y_pred, y_test)\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhSWeuLDgw_a"
      },
      "source": [
        "This model is logically more correct, but the accuracy is worse. In the next section, we'll discuss this paradoxical result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7MYXAfyp0pR"
      },
      "source": [
        "### Bonus: Use a custom distance metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsqZvQppofp7"
      },
      "source": [
        "The accuracy of our model is poor, especially when we we have more NaNs. We saw this when we used ordinal encoding of binary features (which passes through NaNs), and when we changed the one-hot encoder to pass through NaNs.\n",
        "\n",
        "This is due to another problem: our distance metric.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax5GQNCxeT9x"
      },
      "source": [
        "The `nan_euclidean_distance` metric we are using is the only distance metric function in `sklearn` that supports NaN values. However, it is not quite right for our problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGd8KkXpeWuK"
      },
      "source": [
        "Consider these two samples in the data, with only one feature in common - both samples represent female respondents:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV2gBkQkfyll"
      },
      "source": [
        "df_combined_nan.iloc[[0,1889]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx-EE30LgpJP"
      },
      "source": [
        "Notice that the distance between them is 0, even though as far as we know, they have little in common:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ceyj7oZcgKUD"
      },
      "source": [
        "dist = nan_euclidean_distances(df_combined_nan.iloc[0:1].drop('PRES', axis=1),df_combined_nan.iloc[1889:1890].drop('PRES', axis=1))\n",
        "dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhrk-XIujAqM"
      },
      "source": [
        "Now consider another two samples, which agree on multiple features -\n",
        "\n",
        "* both female respondents\n",
        "* both 18-29\n",
        "* both in the Under $30,000 income bracket\n",
        "* both Hispanic/Latino\n",
        "* both agree that foreign policy is a major issue deciding their presidential vote\n",
        "* both agree that 'Has good judgment' is an imnportant quality in a president\n",
        "\n",
        "but which have a minor disagreement on education levels -\n",
        "\n",
        "* one sample has high school education or less,\n",
        "* the other sample has some college or an associate's degree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBCIbwTWhLDR"
      },
      "source": [
        "df_combined_nan.iloc[[0,14826]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgQrYP4Z8Ne9"
      },
      "source": [
        "These two samples have a larger pairwise distance than the previous pair of samples, which had far less in common but no explicit disagreement:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnVbbmk2f9Bk"
      },
      "source": [
        "dist = nan_euclidean_distances(df_combined_nan.iloc[0:1].drop('PRES', axis=1),df_combined_nan.iloc[14826:14827].drop('PRES', axis=1))\n",
        "dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK2BwZrSkNQ4"
      },
      "source": [
        "This behavior of the distance metric leads to a situation where the \"nearest neighbors\" often have very little in common with the test sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9SceWWBkhQd"
      },
      "source": [
        "To address this, we can write a custom distance metric with more desirable behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOw3FSTJkn_a"
      },
      "source": [
        "Suppose we\n",
        "\n",
        "* use an L1 distance computed over the features that are non-NaN for both samples,\n",
        "* normalize it by the number of features used in the distance computation, and\n",
        "* also add a penalty term that is large when the number of features used in the distance computation is small. This will increase the distance between pairs of samples that have very little in common but also very little that they disagree on.\n",
        "\n",
        "$$dist(a,b) = \\frac{\\lVert a - b \\rVert_{\\ell_{1}}}{N_{\\text{non-NaN}}} + \\frac{1}{N_{\\text{non-NaN}}}$$\n",
        "\n",
        "where $N_{\\text{non-NaN}}$ is the number of elements for which both $a$ and $b$ have non-NaN values.\n",
        "\n",
        "(This isn't really a great distance metric, but it's easy to understand and has the characteristics we care about - it will give us a smaller distance for samples that have a lot in common!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6RuGdpC5M77"
      },
      "source": [
        "Our custom distance metric will accept a single sample as its first argument, and a matrix of samples as its second argument.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKhIYW5Xv4F7"
      },
      "source": [
        "def custom_distance(a, b):\n",
        "  dif = np.abs(np.subtract(a,b))\n",
        "  dist_num = 1+np.nansum(dif, axis=1)\n",
        "  dist_den = np.count_nonzero(~np.isnan(dif), axis=1)\n",
        "  return dist_num/dist_den"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E06HEPoCuieL"
      },
      "source": [
        "Now, you can see that the samples with more elements in common, have a smaller distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XERHHQsj62mx"
      },
      "source": [
        "Here is the pairwise distance between the two samples mentioned above, which have only one thing in common - both respondents are female:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_amVGnMmynD"
      },
      "source": [
        "dist = custom_distance(df_combined_nan.iloc[0:1].drop('PRES', axis=1),df_combined_nan.iloc[1889:1890].drop('PRES', axis=1))\n",
        "dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3XBWK5-69Q2"
      },
      "source": [
        "And here is the pairwise distance between the two samples mentioned above, which have many things in common and a small disagreement on education:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfMLjtwwg8fP"
      },
      "source": [
        "dist = custom_distance(df_combined_nan.iloc[0:1].drop('PRES', axis=1),df_combined_nan.iloc[14826:14827].drop('PRES', axis=1))\n",
        "dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzii-OUE7BnE"
      },
      "source": [
        "Let us see whether this custom distance metric helps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq4duIkXs1Qq"
      },
      "source": [
        "We can use the same training and test data from the previous subsection to compute the accuracy of the $k$ nearest neighbors model when we use our custom distance metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFKgWW7zR8oQ"
      },
      "source": [
        "distances_custom = np.zeros(shape=(X_test.shape[0], X_train.shape[0]))\n",
        "distances_custom.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N9OK_C_4INo"
      },
      "source": [
        "for idx in tqdm(range(X_test.shape[0]), total=X_test.shape[0], desc=\"Test samples\"):\n",
        "  distances_custom[idx] = custom_distance(X_test.iloc[idx], X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGDgkTOBq1Sz"
      },
      "source": [
        "y_pred = [y_train.loc[np.argsort(dist)[:k_opt]].mode() for dist in distances_custom]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqBOo211q3ji"
      },
      "source": [
        "acc = accuracy_score(y_pred, y_test)\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJN3nHiIwlzA"
      },
      "source": [
        "With the custom distance metric, the accuracy goes up a bit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q72cwaDdoJc"
      },
      "source": [
        "### Bonus: Use feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vceIvO-37egA"
      },
      "source": [
        "Now that we have fixed the problems with the data preparation and with the distance metric, we can try and improve our model with feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOvWn12TdyBe"
      },
      "source": [
        "Looking at the data, it is clear that some features are much more predictive than others.\n",
        "\n",
        "Here is a plot of the vote breakdown vs. each feature:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jocsZh7vw_DS"
      },
      "source": [
        "fig = plt.figure(figsize=(25,25))\n",
        "\n",
        "for idx, f in enumerate(features):\n",
        "    ax = fig.add_subplot(5,5,idx+1)\n",
        "    versions = df[[f, 'VERSION']].dropna()['VERSION'].unique()\n",
        "    sns.countplot(data=df, x=f, hue='PRES', ax=ax)\n",
        "    ax.set_title(f)\n",
        "    plt.xticks(rotation=15)\n",
        "    plt.title(\"Feature: %s\\n %s\" % (f, np.str.join(', ', versions)))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjFlgF_8Becr"
      },
      "source": [
        "We can see that `HEALTHCARE16` is much more predictive of presidential vote than `SUPREME16` (for example)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P54wCncI7wmu"
      },
      "source": [
        "But, the $k$ nearest neighbors algorithm treats all features as if they are equally important."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe7tltNiBpmc"
      },
      "source": [
        "We may get better results if we exclude certain features from our analysis, rather than using all features (as we have above). Also, the distance computations will be faster with a smaller number of features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKk2gLzd9VpY"
      },
      "source": [
        "How should we select the features to include in our model?\n",
        "\n",
        "There are a few general approaches to feature selection:\n",
        "\n",
        "* **Wrapper methods** use the ML model on the data, and  select relevant features based the model performance. (For example, we might train a linear regression on different combinations of features, and the then select the one that has the best performance on a validation set.)\n",
        "* **Filter methods** use statistical characteristics of the data to select the features that are more useful for predicting the target variable. (For example, we might select the features that have the highest correlation with the target variable.)\n",
        "* **Embedded methods** do feature selection \"automatically\" as part of the model training. (LASSO is an example of this type of feature selection.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S75uOQmk-pdE"
      },
      "source": [
        "We also need to decide whether we want to take the dependencies between features into account, or not.\n",
        "\n",
        "With **univariate feature selection**, we consider each feature independently. For example, we might score each feature according to its correlation with the target variable, then pick the features with the highest scores.\n",
        "\n",
        "The problem with univariate feature selection is that some features may carry redundant information. In that case, we don't gain much from having both features in our model, but both will have similar scores.\n",
        "\n",
        "As an alternative to univariate feature selection, we might consider **greedy feature selection**:\n",
        "\n",
        "* Let $S^{t-1}$ be the set of selected features at time ${t-1}$.\n",
        "* Compute the score for all combinations of the current set of features + one more feature\n",
        "* For the next time step $S^t$, add the feature that gave you the best score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs1gejYn_HIj"
      },
      "source": [
        "In the following example, we are going to use a **filter method** and **univariate feature selection**, because these are cheaper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCxPhKf8BTjJ"
      },
      "source": [
        "We have one last decision to make: what statistic to use to score our features? In the example below, we use mutual information to rank the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuVW9EubzoDe"
      },
      "source": [
        "cols = df_combined_nan.drop('PRES', axis=1).columns\n",
        "cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxNZ2OnWzUC_"
      },
      "source": [
        "from sklearn.feature_selection import mutual_info_classif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVXnC3CBzjPj"
      },
      "source": [
        "col_weights = np.zeros(df_combined_nan.drop('PRES', axis=1).shape[1])\n",
        "for idx, c in enumerate(cols):\n",
        "  df_col = pd.concat([X_train[c], y_train], axis=1).dropna()\n",
        "  col_weights[idx] = mutual_info_classif(np.array(df_col[c]).reshape(-1,1), df_col['PRES'], discrete_features=True, n_neighbors=51)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(col_weights)"
      ],
      "metadata": {
        "id": "CA7h2AOHQpXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-kMWVfzzyRV"
      },
      "source": [
        "cols[np.argsort(col_weights)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhIikhXTqTcH"
      },
      "source": [
        "Now let's choose the \"best\" number of features by CV.\n",
        "\n",
        "(This will take a while, so start it running, then walk away and come back in a couple of hours.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUGH6GRJTKw_"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "n_fold = 5\n",
        "nfeature_list = np.arange(10, len(cols), 1)\n",
        "n_f = len(nfeature_list)\n",
        "acc_feature_list = np.zeros((n_f, n_fold))\n",
        "\n",
        "distances_feature_selection = np.zeros(shape=(X_train.shape[0], X_train.shape[0]))\n",
        "\n",
        "kf = KFold(n_splits=n_fold)\n",
        "kf.get_n_splits(X_train)\n",
        "\n",
        "for idx_n, n in tqdm(enumerate(nfeature_list), total=n_f, desc=\"N features\"):\n",
        "\n",
        "  keep_columns = cols[np.argsort(col_weights)[-n:]]\n",
        "\n",
        "  for idx_train in range(X_train.shape[0]):\n",
        "    distances_feature_selection[idx_train] = custom_distance(X_train[keep_columns].iloc[idx_train], X_train[keep_columns])\n",
        "\n",
        "  for isplit, idx in enumerate(kf.split(X_train)):\n",
        "\n",
        "    train_index, val_index = idx\n",
        "\n",
        "    y_train_kfold = y_train.iloc[train_index]\n",
        "    y_val_kfold = y_train.iloc[val_index]\n",
        "\n",
        "    y_train_kfold.reset_index(drop=True, inplace=True)\n",
        "    y_val_kfold.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    distances_val_kfold = distances_feature_selection[val_index[:, None], train_index]\n",
        "\n",
        "    y_pred = [y_train_kfold.loc[np.argsort(dist)[:k_opt]].mode()[0] for dist in distances_val_kfold]\n",
        "    acc_feature_list[idx_n, isplit] = accuracy_score(np.array(y_val_kfold), np.array(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7X8bt0pm2ZF"
      },
      "source": [
        "plt.errorbar(x=nfeature_list, y=acc_feature_list.mean(axis=1), yerr=acc_feature_list.std(axis=1)/np.sqrt(n_fold-1));\n",
        "\n",
        "plt.xlabel(\"Number of features\");\n",
        "plt.ylabel(\"K-fold accuracy\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bge7LPyx-st"
      },
      "source": [
        "n_opt=nfeature_list[np.argmax(acc_feature_list.mean(axis=1))]\n",
        "print(n_opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLU41FLmy09h"
      },
      "source": [
        "According to the K-fold CV, these are the features we should use to fit our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9OlLIQtyZ-T"
      },
      "source": [
        "keep_columns = cols[np.argsort(col_weights)[-n_opt:]]\n",
        "keep_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0aBBJM2TDB7"
      },
      "source": [
        "We can re-fit our model using only those features, and then evaluate it on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubuiuP-U-g2Y"
      },
      "source": [
        "distances_feature_selection = np.zeros(shape=(X_test.shape[0], X_train.shape[0]))\n",
        "for idx_test in range(X_test.shape[0]):\n",
        "  distances_feature_selection[idx_test] = custom_distance(X_test[keep_columns].iloc[idx_test], X_train[keep_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r74Yq41fyU7Y"
      },
      "source": [
        "y_pred = np.array([y_train.loc[np.argsort(dist)[:k_opt]].mode() for dist in distances_feature_selection]).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQtTAr68yR5g"
      },
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVHwhDaeVrFt"
      },
      "source": [
        "### Bonus: Use feature weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEdrKwc0U900"
      },
      "source": [
        "As an alternative to feature selection, where we completely disregard some features, we can potentially improve performance by using all features but *weighting* them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnWwR-PITaQu"
      },
      "source": [
        "The features that are more informative regarding the target variable will be weighted more heavily than those that are not so informative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sveXR5aySzMS"
      },
      "source": [
        "This has the advantage of not throwing out useful information; on the other hand, we don't get the benefit of faster computation, as we did with feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVbHMnniTbOk"
      },
      "source": [
        "We can use the mutual information statistic we computed earlier to weight our columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnTEifs53AND"
      },
      "source": [
        "X_train_weighted = X_train.multiply(col_weights)\n",
        "X_test_weighted = X_test.multiply(col_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgxekNIQ4SFw"
      },
      "source": [
        "X_train_weighted.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHZTEw5QTfau"
      },
      "source": [
        "Now, we'll re-compute distances for the weighted columns (using *all* columns):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgTq8EAERx4H"
      },
      "source": [
        "distances_custom_weighted = np.zeros(shape=(X_test_weighted.shape[0], X_train_weighted.shape[0]))\n",
        "distances_custom_weighted.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaGh6sQTWTYE"
      },
      "source": [
        "for idx in tqdm(range(X_test_weighted.shape[0]), total=X_test_weighted.shape[0], desc=\"Test samples\"):\n",
        "  distances_custom_weighted[idx] = custom_distance(X_test_weighted.iloc[idx], X_train_weighted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3yUpiq9Tmxi"
      },
      "source": [
        "And evaluate the model performance on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWwziCReWaBy"
      },
      "source": [
        "y_pred = [y_train.loc[np.argsort(dist)[:k_opt]].mode() for dist in distances_custom_weighted]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZUIYvFBWflN"
      },
      "source": [
        "acc = accuracy_score(y_pred, y_test)\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}